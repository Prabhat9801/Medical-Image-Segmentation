{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Medical Image Segmentation - Google Colab Training\n",
                "\n",
                "**Project:** Comparing UNet, UNet++, and TransUNet on ISIC Dataset\n",
                "\n",
                "**Author:** Prabhat\n",
                "\n",
                "---\n",
                "\n",
                "## üìã Training Plan\n",
                "\n",
                "We'll train 3 models √ó 4 data fractions = **12 experiments**\n",
                "\n",
                "| Model | 10% | 25% | 50% | 100% |\n",
                "|-------|-----|-----|-----|------|\n",
                "| UNet | ‚úì | ‚úì | ‚úì | ‚úì |\n",
                "| UNet++ | ‚úì | ‚úì | ‚úì | ‚úì |\n",
                "| TransUNet | ‚úì | ‚úì | ‚úì | ‚úì |\n",
                "\n",
                "**Estimated Time:** 6-8 hours total"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup: Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA version: {torch.version.cuda}\")\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
                "    print(\"Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone Repository"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone your GitHub repository\n",
                "!git clone https://github.com/Prabhat9801/Medical-Image-Segmentation.git\n",
                "%cd Medical-Image-Segmentation\n",
                "\n",
                "# Verify\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q timm albumentations opencv-python-headless tqdm\n",
                "\n",
                "print(\"‚úÖ Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Verify your zip file is there\n",
                "!ls -lh /content/drive/MyDrive/*.zip"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Extract Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import zipfile\n",
                "import os\n",
                "\n",
                "# Path to your zip file in Google Drive\n",
                "zip_path = \"/content/drive/MyDrive/isic_processed_256.zip\"\n",
                "extract_path = \"/content/Medical-Image-Segmentation/data/processed\"\n",
                "\n",
                "# Create directory\n",
                "os.makedirs(extract_path, exist_ok=True)\n",
                "\n",
                "# Extract\n",
                "print(\"üì¶ Extracting data... (this may take 2-3 minutes)\")\n",
                "with zipfile.ZipFile(zip_path, 'r') as z:\n",
                "    z.extractall(extract_path)\n",
                "\n",
                "print(\"‚úÖ Extraction complete!\")\n",
                "\n",
                "# Verify\n",
                "!ls -lh data/processed/isic/\n",
                "!echo \"\\nChecking splits.csv:\"\n",
                "!head -5 data/processed/isic/splits.csv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Test Run (Quick Verification)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test with UNet, 10% data, 2 epochs\n",
                "# This should take ~2-3 minutes\n",
                "\n",
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 2 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.1 \\\n",
                "    --lr 1e-4\n",
                "\n",
                "print(\"\\n‚úÖ Test run complete! If this worked, proceed with full training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Full Training - UNet (All Data Fractions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet - 10% data (~15-20 minutes)\n",
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.1 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet - 25% data (~30-40 minutes)\n",
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.25 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet - 50% data (~1 hour)\n",
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.5 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet - 100% data (~2 hours)\n",
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 1.0 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Full Training - UNet++ (All Data Fractions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet++ - 10% data\n",
                "!python -m src.train \\\n",
                "    --model unetpp \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.1 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet++ - 25% data\n",
                "!python -m src.train \\\n",
                "    --model unetpp \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.25 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet++ - 50% data\n",
                "!python -m src.train \\\n",
                "    --model unetpp \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 0.5 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# UNet++ - 100% data\n",
                "!python -m src.train \\\n",
                "    --model unetpp \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 8 \\\n",
                "    --data_fraction 1.0 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9Ô∏è‚É£ Full Training - TransUNet (All Data Fractions)\n",
                "\n",
                "**Note:** TransUNet uses smaller batch size (4) due to higher memory requirements"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TransUNet - 10% data (~45 min)\n",
                "!python -m src.train \\\n",
                "    --model transunet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 4 \\\n",
                "    --data_fraction 0.1 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TransUNet - 25% data (~1.5 hours)\n",
                "!python -m src.train \\\n",
                "    --model transunet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 4 \\\n",
                "    --data_fraction 0.25 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TransUNet - 50% data (~3 hours)\n",
                "!python -m src.train \\\n",
                "    --model transunet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 4 \\\n",
                "    --data_fraction 0.5 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TransUNet - 100% data (~6 hours)\n",
                "!python -m src.train \\\n",
                "    --model transunet \\\n",
                "    --epochs 30 \\\n",
                "    --batch_size 4 \\\n",
                "    --data_fraction 1.0 \\\n",
                "    --lr 1e-4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîü View Training Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List all experiments\n",
                "!ls -lh experiments/"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View training history for a specific experiment\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Replace with your actual experiment folder name\n",
                "exp_folder = \"experiments/unet_10pct_TIMESTAMP\"  # UPDATE THIS\n",
                "\n",
                "with open(f\"{exp_folder}/history.json\", 'r') as f:\n",
                "    history = json.load(f)\n",
                "\n",
                "# Plot\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "ax1.plot(history['train_loss'], label='Train')\n",
                "ax1.plot(history['val_loss'], label='Val')\n",
                "ax1.set_title('Loss')\n",
                "ax1.legend()\n",
                "\n",
                "ax2.plot(history['train_dice'], label='Train')\n",
                "ax2.plot(history['val_dice'], label='Val')\n",
                "ax2.set_title('Dice Score')\n",
                "ax2.legend()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£1Ô∏è‚É£ Evaluate Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate UNet 10% model\n",
                "# Replace with your actual experiment folder\n",
                "!python -m src.eval \\\n",
                "    --model unet \\\n",
                "    --checkpoint experiments/unet_10pct_TIMESTAMP/best_model.pt \\\n",
                "    --num_vis 8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View evaluation results\n",
                "from IPython.display import Image, display\n",
                "\n",
                "# Display predictions\n",
                "display(Image('reports/figures/best_model/predictions.png'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£2Ô∏è‚É£ Save Results to Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create backup folders in Drive\n",
                "!mkdir -p /content/drive/MyDrive/medseg_experiments\n",
                "!mkdir -p /content/drive/MyDrive/medseg_reports\n",
                "\n",
                "# Copy all experiments\n",
                "print(\"üì¶ Copying experiments to Google Drive...\")\n",
                "!cp -r experiments/* /content/drive/MyDrive/medseg_experiments/\n",
                "\n",
                "# Copy reports\n",
                "print(\"üì¶ Copying reports to Google Drive...\")\n",
                "!cp -r reports/* /content/drive/MyDrive/medseg_reports/\n",
                "\n",
                "print(\"\\n‚úÖ All results saved to Google Drive!\")\n",
                "print(\"üìÇ Location: MyDrive/medseg_experiments/ and MyDrive/medseg_reports/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£3Ô∏è‚É£ Create Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import glob\n",
                "import json\n",
                "\n",
                "# Collect all results\n",
                "results_files = glob.glob('reports/figures/*/results.json')\n",
                "\n",
                "summary_data = []\n",
                "\n",
                "for result_file in results_files:\n",
                "    with open(result_file, 'r') as f:\n",
                "        data = json.load(f)\n",
                "    \n",
                "    summary_data.append({\n",
                "        'Model': data['model'],\n",
                "        'Checkpoint': data['checkpoint'].split('/')[-2],\n",
                "        'Dice': f\"{data['metrics']['dice']['mean']:.4f}\",\n",
                "        'IoU': f\"{data['metrics']['iou']['mean']:.4f}\",\n",
                "        'Accuracy': f\"{data['metrics']['accuracy']['mean']:.4f}\"\n",
                "    })\n",
                "\n",
                "summary_df = pd.DataFrame(summary_data)\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üìä RESULTS SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(summary_df.to_string(index=False))\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Save to CSV\n",
                "summary_df.to_csv('results_summary.csv', index=False)\n",
                "!cp results_summary.csv /content/drive/MyDrive/\n",
                "\n",
                "print(\"\\n‚úÖ Summary saved to Google Drive as results_summary.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÖ Training Complete!\n",
                "\n",
                "### Next Steps:\n",
                "\n",
                "1. **Download results** from Google Drive:\n",
                "   - `medseg_experiments/` folder\n",
                "   - `medseg_reports/` folder\n",
                "   - `results_summary.csv`\n",
                "\n",
                "2. **Complete the report** (`reports/report.md`):\n",
                "   - Fill in actual performance numbers\n",
                "   - Add visualizations\n",
                "   - Write analysis\n",
                "\n",
                "3. **Create presentation** using the figures\n",
                "\n",
                "4. **Update README** with findings\n",
                "\n",
                "---\n",
                "\n",
                "**üéâ Congratulations on completing the training!**"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}