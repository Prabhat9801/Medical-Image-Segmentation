{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Medical Image Segmentation - UNet Training\n",
                "\n",
                "This notebook trains **UNet** models on different data fractions (10%, 25%, 50%, 100%).\n",
                "\n",
                "**Runtime:** ~2-3 hours on Colab GPU\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Setup GPU Runtime\n",
                "\n",
                "‚ö†Ô∏è **IMPORTANT:** Make sure you're using a GPU runtime!\n",
                "- Go to: **Runtime ‚Üí Change runtime type ‚Üí GPU**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify GPU is available\n",
                "import torch\n",
                "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Clone Repository"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/Prabhat9801/Medical-Image-Segmentation.git\n",
                "%cd Medical-Image-Segmentation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q timm albumentations opencv-python-headless tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Mount Google Drive & Extract Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import zipfile\n",
                "import os\n",
                "import shutil\n",
                "import pandas as pd\n",
                "\n",
                "# Paths\n",
                "zip_path = \"/content/drive/MyDrive/isic_processed_256.zip\"\n",
                "final_path = \"/content/Medical-Image-Segmentation/data/processed/isic\"\n",
                "\n",
                "print(\"üì¶ Extracting data with Windows path fix...\")\n",
                "\n",
                "# Remove existing if present\n",
                "if os.path.exists(final_path):\n",
                "    shutil.rmtree(final_path)\n",
                "\n",
                "# Create the directory structure\n",
                "os.makedirs(final_path, exist_ok=True)\n",
                "os.makedirs(os.path.join(final_path, \"images\"), exist_ok=True)\n",
                "os.makedirs(os.path.join(final_path, \"masks\"), exist_ok=True)\n",
                "\n",
                "# Extract and fix Windows paths\n",
                "with zipfile.ZipFile(zip_path, 'r') as z:\n",
                "    for file_info in z.filelist:\n",
                "        orig_name = file_info.filename\n",
                "        fixed_name = orig_name.replace('\\\\', '/')\n",
                "        \n",
                "        if fixed_name.startswith('isic/'):\n",
                "            fixed_name = fixed_name[5:]\n",
                "        \n",
                "        if 'images/' in fixed_name or (fixed_name.endswith('.png') and 'mask' not in fixed_name.lower()):\n",
                "            filename = os.path.basename(fixed_name)\n",
                "            target_path = os.path.join(final_path, \"images\", filename)\n",
                "        elif 'masks/' in fixed_name or '_mask.png' in fixed_name:\n",
                "            filename = os.path.basename(fixed_name)\n",
                "            target_path = os.path.join(final_path, \"masks\", filename)\n",
                "        elif fixed_name.endswith('splits.csv'):\n",
                "            target_path = os.path.join(final_path, \"splits.csv\")\n",
                "        else:\n",
                "            continue\n",
                "        \n",
                "        with z.open(file_info) as source, open(target_path, 'wb') as target:\n",
                "            shutil.copyfileobj(source, target)\n",
                "\n",
                "print(\"‚úÖ Extraction complete!\")\n",
                "\n",
                "# Fix splits.csv paths\n",
                "print(\"\\nüîß Fixing splits.csv paths...\")\n",
                "splits_path = os.path.join(final_path, \"splits.csv\")\n",
                "if os.path.exists(splits_path):\n",
                "    df = pd.read_csv(splits_path)\n",
                "    \n",
                "    # Fix paths to absolute Colab paths\n",
                "    df['image_path'] = df['image_path'].apply(\n",
                "        lambda x: os.path.join(final_path, \"images\", os.path.basename(x))\n",
                "    )\n",
                "    df['mask_path'] = df['mask_path'].apply(\n",
                "        lambda x: os.path.join(final_path, \"masks\", os.path.basename(x))\n",
                "    )\n",
                "    \n",
                "    df.to_csv(splits_path, index=False)\n",
                "    print(\"‚úÖ splits.csv paths fixed!\")\n",
                "\n",
                "# Verify\n",
                "import glob\n",
                "image_count = len(glob.glob(os.path.join(final_path, \"images\", \"*.png\")))\n",
                "mask_count = len(glob.glob(os.path.join(final_path, \"masks\", \"*.png\")))\n",
                "\n",
                "print(f\"\\n‚úÖ Images: {image_count}\")\n",
                "print(f\"‚úÖ Masks: {mask_count}\")\n",
                "print(f\"‚úÖ splits.csv: {'Found' if os.path.exists(splits_path) else 'NOT FOUND'}\")\n",
                "print(\"\\nüéâ Data extraction successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Train UNet - 10% Data\n",
                "\n",
                "**Expected time:** ~15-20 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 50 \\\n",
                "    --batch_size 16 \\\n",
                "    --data_fraction 0.1 \\\n",
                "    --lr 1e-4\n",
                "\n",
                "print(\"\\n‚úÖ UNet 10% training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Train UNet - 25% Data\n",
                "\n",
                "**Expected time:** ~30-40 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 50 \\\n",
                "    --batch_size 16 \\\n",
                "    --data_fraction 0.25 \\\n",
                "    --lr 1e-4\n",
                "\n",
                "print(\"\\n‚úÖ UNet 25% training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Train UNet - 50% Data\n",
                "\n",
                "**Expected time:** ~50-60 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 50 \\\n",
                "    --batch_size 16 \\\n",
                "    --data_fraction 0.5 \\\n",
                "    --lr 1e-4\n",
                "\n",
                "print(\"\\n‚úÖ UNet 50% training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Train UNet - 100% Data\n",
                "\n",
                "**Expected time:** ~90-120 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m src.train \\\n",
                "    --model unet \\\n",
                "    --epochs 50 \\\n",
                "    --batch_size 16 \\\n",
                "    --data_fraction 1.0 \\\n",
                "    --lr 1e-4\n",
                "\n",
                "print(\"\\n‚úÖ UNet 100% training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Save Results to Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy all experiments to Google Drive\n",
                "!mkdir -p /content/drive/MyDrive/medical_segmentation_results\n",
                "!cp -r experiments /content/drive/MyDrive/medical_segmentation_results/unet_experiments\n",
                "\n",
                "print(\"\\n‚úÖ All UNet results saved to Google Drive!\")\n",
                "print(\"üìÅ Location: /content/drive/MyDrive/medical_segmentation_results/unet_experiments\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ UNet Training Complete!\n",
                "\n",
                "**Next steps:**\n",
                "1. Run `COLAB_TRAIN_UNETPP.ipynb` to train UNet++\n",
                "2. Run `COLAB_TRAIN_TRANSUNET.ipynb` to train TransUNet\n",
                "3. Run `COLAB_RESULTS.ipynb` to evaluate and compare all models"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}