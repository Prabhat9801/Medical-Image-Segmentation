{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC Dataset Preprocessing\n",
    "\n",
    "This notebook preprocesses the ISIC 2018 Task 1 dataset for skin lesion segmentation.\n",
    "\n",
    "**Steps:**\n",
    "1. Load raw images and masks\n",
    "2. Resize to 256x256\n",
    "3. Normalize images\n",
    "4. Ensure masks are binary\n",
    "5. Create train/val/test splits\n",
    "6. Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "RAW_IMAGES_DIR = '../data/raw/isic/images'\n",
    "RAW_MASKS_DIR = '../data/raw/isic/masks'\n",
    "\n",
    "PROCESSED_IMAGES_DIR = '../data/processed/isic/images'\n",
    "PROCESSED_MASKS_DIR = '../data/processed/isic/masks'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(PROCESSED_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_MASKS_DIR, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "TARGET_SIZE = (256, 256)\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of images and masks\n",
    "image_files = sorted([f for f in os.listdir(RAW_IMAGES_DIR) if f.endswith(('.jpg', '.png'))])\n",
    "mask_files = sorted([f for f in os.listdir(RAW_MASKS_DIR) if f.endswith('.png')])\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "print(f\"Found {len(mask_files)} masks\")\n",
    "\n",
    "# Match images with masks\n",
    "# Assuming masks have '_segmentation' suffix or similar\n",
    "# Adjust this based on your actual file naming convention\n",
    "image_mask_pairs = []\n",
    "\n",
    "for img_file in image_files:\n",
    "    # Extract base name (without extension)\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    \n",
    "    # Find corresponding mask\n",
    "    # Try different naming conventions\n",
    "    possible_mask_names = [\n",
    "        f\"{base_name}_segmentation.png\",\n",
    "        f\"{base_name}.png\",\n",
    "        f\"{base_name}_mask.png\"\n",
    "    ]\n",
    "    \n",
    "    for mask_name in possible_mask_names:\n",
    "        if mask_name in mask_files:\n",
    "            image_mask_pairs.append((img_file, mask_name))\n",
    "            break\n",
    "\n",
    "print(f\"\\nMatched {len(image_mask_pairs)} image-mask pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few samples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    img_file, mask_file = image_mask_pairs[i]\n",
    "    \n",
    "    # Load image and mask\n",
    "    img = Image.open(os.path.join(RAW_IMAGES_DIR, img_file))\n",
    "    mask = Image.open(os.path.join(RAW_MASKS_DIR, mask_file))\n",
    "    \n",
    "    # Display\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 0].set_title(f'Image {i+1} ({img.size})')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title(f'Mask {i+1} ({mask.size})')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess and Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, output_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load, resize, and save image.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(target_size, Image.BILINEAR)\n",
    "    img.save(output_path)\n",
    "    return img\n",
    "\n",
    "def preprocess_mask(mask_path, output_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load, resize, binarize, and save mask.\n",
    "    \"\"\"\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    mask = mask.resize(target_size, Image.NEAREST)  # Use NEAREST for masks\n",
    "    \n",
    "    # Binarize (threshold at 127)\n",
    "    mask_array = np.array(mask)\n",
    "    mask_array = (mask_array > 127).astype(np.uint8) * 255\n",
    "    \n",
    "    mask = Image.fromarray(mask_array)\n",
    "    mask.save(output_path)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images and masks\n",
    "processed_pairs = []\n",
    "\n",
    "print(\"Processing images and masks...\")\n",
    "for img_file, mask_file in tqdm(image_mask_pairs):\n",
    "    # Generate output filenames\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    \n",
    "    output_img_name = f\"{base_name}.png\"\n",
    "    output_mask_name = f\"{base_name}_mask.png\"\n",
    "    \n",
    "    output_img_path = os.path.join(PROCESSED_IMAGES_DIR, output_img_name)\n",
    "    output_mask_path = os.path.join(PROCESSED_MASKS_DIR, output_mask_name)\n",
    "    \n",
    "    # Preprocess\n",
    "    try:\n",
    "        preprocess_image(\n",
    "            os.path.join(RAW_IMAGES_DIR, img_file),\n",
    "            output_img_path,\n",
    "            TARGET_SIZE\n",
    "        )\n",
    "        \n",
    "        preprocess_mask(\n",
    "            os.path.join(RAW_MASKS_DIR, mask_file),\n",
    "            output_mask_path,\n",
    "            TARGET_SIZE\n",
    "        )\n",
    "        \n",
    "        processed_pairs.append((output_img_path, output_mask_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(processed_pairs)} pairs successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(processed_pairs, columns=['image_path', 'mask_path'])\n",
    "\n",
    "# Split into train/temp\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=(VAL_RATIO + TEST_RATIO), \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Split temp into val/test\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=TEST_RATIO / (VAL_RATIO + TEST_RATIO),\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Add split column\n",
    "train_df['split'] = 'train'\n",
    "val_df['split'] = 'val'\n",
    "test_df['split'] = 'test'\n",
    "\n",
    "# Combine\n",
    "splits_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Val samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Total: {len(splits_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits CSV\n",
    "splits_csv_path = '../data/processed/isic/splits.csv'\n",
    "splits_df.to_csv(splits_csv_path, index=False)\n",
    "print(f\"\\nSplits saved to: {splits_csv_path}\")\n",
    "\n",
    "# Display first few rows\n",
    "splits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Small Split for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small subset (100-200 samples)\n",
    "small_train = train_df.sample(n=min(100, len(train_df)), random_state=RANDOM_SEED)\n",
    "small_val = val_df.sample(n=min(30, len(val_df)), random_state=RANDOM_SEED)\n",
    "small_test = test_df.sample(n=min(30, len(test_df)), random_state=RANDOM_SEED)\n",
    "\n",
    "small_splits_df = pd.concat([small_train, small_val, small_test], ignore_index=True)\n",
    "\n",
    "# Save small splits\n",
    "small_splits_csv_path = '../data/processed/isic/splits_small.csv'\n",
    "small_splits_df.to_csv(small_splits_csv_path, index=False)\n",
    "\n",
    "print(f\"Small split created:\")\n",
    "print(f\"  Train: {len(small_train)}\")\n",
    "print(f\"  Val: {len(small_val)}\")\n",
    "print(f\"  Test: {len(small_test)}\")\n",
    "print(f\"\\nSaved to: {small_splits_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize processed samples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    row = splits_df.iloc[i]\n",
    "    \n",
    "    # Load processed image and mask\n",
    "    img = Image.open(row['image_path'])\n",
    "    mask = Image.open(row['mask_path'])\n",
    "    \n",
    "    # Display\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 0].set_title(f'Processed Image {i+1} ({img.size})')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title(f'Processed Mask {i+1} ({mask.size})')\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mask statistics\n",
    "mask_ratios = []\n",
    "\n",
    "for _, row in splits_df.head(100).iterrows():\n",
    "    mask = np.array(Image.open(row['mask_path']))\n",
    "    ratio = (mask > 127).sum() / mask.size\n",
    "    mask_ratios.append(ratio)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(mask_ratios, bins=30, edgecolor='black')\n",
    "plt.xlabel('Lesion Area Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Lesion Area in Masks (First 100 samples)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean lesion area ratio: {np.mean(mask_ratios):.3f}\")\n",
    "print(f\"Std lesion area ratio: {np.std(mask_ratios):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Preprocessing completed!**\n",
    "\n",
    "**Next steps:**\n",
    "1. Zip the `data/processed/isic/` folder\n",
    "2. Upload to Google Drive as `isic_processed_256.zip`\n",
    "3. Push code to GitHub\n",
    "4. Continue with training in Google Colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
